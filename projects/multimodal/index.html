<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Building a Multimodal Generative AI Assistant | Abir Arsalane</title>
<meta name="keywords" content="LLM, AI, GenAI, Hugging Face, RAG, Fine-tuning, Python">
<meta name="description" content="Building a Multimodal Generative AI Assistant.">
<meta name="author" content="">
<link rel="canonical" href="https://abirarsalane.github.io/projects/multimodal/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.a72801f0f40a8d7f71aa1cafd1c2f2a993a1f26ca1cfd38fdba65d5b9b0f08a0.css" integrity="sha256-pygB8PQKjX9xqhyv0cLyqZOh8myhz9OP26ZdW5sPCKA=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.b95bacdc39e37a332a9f883b1e78be4abc1fdca2bc1f2641f55e3cd3dabd4d61.js" integrity="sha256-uVus3DnjejMqn4g7Hni&#43;Srwf3KK8HyZB9V4809q9TWE="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://abirarsalane.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://abirarsalane.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://abirarsalane.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://abirarsalane.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://abirarsalane.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Building a Multimodal Generative AI Assistant" />
<meta property="og:description" content="Building a Multimodal Generative AI Assistant." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://abirarsalane.github.io/projects/multimodal/" />
<meta property="og:image" content="https://abirarsalane.github.io/projects/multimodal/multimodal.png" /><meta property="article:section" content="projects" />



<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://abirarsalane.github.io/projects/multimodal/multimodal.png" />
<meta name="twitter:title" content="Building a Multimodal Generative AI Assistant"/>
<meta name="twitter:description" content="Building a Multimodal Generative AI Assistant."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Projects",
      "item": "https://abirarsalane.github.io/projects/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Building a Multimodal Generative AI Assistant",
      "item": "https://abirarsalane.github.io/projects/multimodal/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Building a Multimodal Generative AI Assistant",
  "name": "Building a Multimodal Generative AI Assistant",
  "description": "Building a Multimodal Generative AI Assistant.",
  "keywords": [
    "LLM", "AI", "GenAI", "Hugging Face", "RAG", "Fine-tuning", "Python"
  ],
  "articleBody": "Introduction I’m thrilled to present my latest project, Multimodal Generative AI. This project combines advanced AI technologies to create a versatile application that showcases the power of modern generative and recognition systems. It integrates text generation, image recognition, and speech processing into a cohesive application, leveraging state-of-the-art models and frameworks.\nTechnical Marvels: Models, Frameworks, and Fine-Tuning 1. Models from Hugging Face and PyTorch We explored a variety of models to identify the best fits for our application. Our selection balances accuracy, fluency, and computational efficiency:\nText Generation: We used the EleutherAI/gpt-neo-2.7B model for generating coherent and contextually relevant text based on a given prompt. Image Recognition: For classifying images, we leveraged the pre-trained EfficientNet-B0 model from PyTorch, known for its efficiency and accuracy. Speech to Text: Utilizing the SpeechRecognition library, we implemented speech-to-text capabilities to convert spoken language into written text. Text to Speech: The gTTS (Google Text-to-Speech) library was used to convert written text into spoken audio, ensuring natural and expressive speech synthesis. 2. FastAPI Framework To build a robust and scalable backend, we employed the FastAPI framework. Its fast performance and intuitive design allowed us to create an API that efficiently handles requests for text generation, image recognition, and speech processing.\n3. Gradio Interface For a user-friendly interface, we turned to Gradio. This framework enabled us to build an interactive web application where users can easily interact with our multimodal AI system. Gradio’s simplicity and flexibility made it the perfect choice for developing a seamless user experience.\nModel Integration and Workflow Our application seamlessly integrates different AI models and workflows to provide a comprehensive user experience:\nText Generation: Users input a prompt, and the GPT-Neo model generates a detailed and contextually appropriate response. Image Recognition: Users upload an image, which is then processed by the EfficientNet-B0 model to provide accurate classification results. Speech to Text: Users upload an audio file, and our system transcribes the speech into text using the SpeechRecognition library. Text to Speech: Users provide text input, and our application converts it into spoken audio using gTTS. Interactive Interface: Gradio A powerful application needs a powerful interface. We crafted an intuitive web app with Gradio that allows users to effortlessly interact with our multimodal AI system. The interface features input fields for text, image, and audio uploads, providing a smooth and engaging user experience.\nText Generation Interface: Users enter a prompt and receive a generated text response. Image Recognition Interface: Users upload an image and receive classification results. Speech to Text Interface: Users upload an audio file and receive the transcribed text. Text to Speech Interface: Users enter text and receive synthesized speech output. Conclusion The Multimodal Generative AI project demonstrates the integration of multiple advanced AI technologies into a cohesive application, providing functionalities like text generation, image recognition, and speech processing. By leveraging modern frameworks and libraries, this project showcases the capabilities of generative and recognition systems, making it a comprehensive and advanced AI project.\n",
  "wordCount" : "490",
  "inLanguage": "en",
  "image":"https://abirarsalane.github.io/projects/multimodal/multimodal.png","datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://abirarsalane.github.io/projects/multimodal/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Abir Arsalane",
    "logo": {
      "@type": "ImageObject",
      "url": "https://abirarsalane.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header sticky-header">
    <nav class="nav">
        <div class="logo">
            <a href="https://abirarsalane.github.io/" accesskey="h" title="Abir Arsalane (Alt + H)">Abir Arsalane</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://abirarsalane.github.io/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://abirarsalane.github.io/blog" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://abirarsalane.github.io/projects" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="https://abirarsalane.github.io/experience" title="Experience">
                    <span>Experience</span>
                </a>
            </li>
            <li>
                <a href="https://abirarsalane.github.io/achievements" title="Achievements">
                    <span>Achievements</span>
                </a>
            </li>
            <li>
                <a href="https://abirarsalane.github.io/search" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://abirarsalane.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://abirarsalane.github.io/projects/">Projects</a></div>
    <h1 class="post-title">
      Building a Multimodal Generative AI Assistant
    </h1>
    <div class="post-description">
      Building a Multimodal Generative AI Assistant.
    </div>
    <div class="post-meta">


Dec 2023

</div>
  </header> 
<figure class="entry-cover"><img loading="lazy" src="https://abirarsalane.github.io/projects/multimodal/multimodal.png" alt="">
        
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">‎ Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#technical-marvels-models-frameworks-and-fine-tuning" aria-label="Technical Marvels: Models, Frameworks, and Fine-Tuning">Technical Marvels: Models, Frameworks, and Fine-Tuning</a><ul>
                        
                <li>
                    <a href="#1-models-from-hugging-face-and-pytorch" aria-label="1. Models from Hugging Face and PyTorch">1. Models from Hugging Face and PyTorch</a></li>
                <li>
                    <a href="#2-fastapi-framework" aria-label="2. FastAPI Framework">2. FastAPI Framework</a></li>
                <li>
                    <a href="#3-gradio-interface" aria-label="3. Gradio Interface">3. Gradio Interface</a></li></ul>
                </li>
                <li>
                    <a href="#model-integration-and-workflow" aria-label="Model Integration and Workflow">Model Integration and Workflow</a></li>
                <li>
                    <a href="#interactive-interface-gradio" aria-label="Interactive Interface: Gradio">Interactive Interface: Gradio</a></li>
                <li>
                    <a href="#conclusion" aria-label="Conclusion">Conclusion</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h1>
<p>I&rsquo;m thrilled to present my latest project, <strong>Multimodal Generative AI</strong>. This project combines advanced AI technologies to create a versatile application that showcases the power of modern generative and recognition systems. It integrates text generation, image recognition, and speech processing into a cohesive application, leveraging state-of-the-art models and frameworks.</p>
<h1 id="technical-marvels-models-frameworks-and-fine-tuning">Technical Marvels: Models, Frameworks, and Fine-Tuning<a hidden class="anchor" aria-hidden="true" href="#technical-marvels-models-frameworks-and-fine-tuning">#</a></h1>
<h2 id="1-models-from-hugging-face-and-pytorch">1. Models from Hugging Face and PyTorch<a hidden class="anchor" aria-hidden="true" href="#1-models-from-hugging-face-and-pytorch">#</a></h2>
<p>We explored a variety of models to identify the best fits for our application. Our selection balances accuracy, fluency, and computational efficiency:</p>
<ul>
<li><strong>Text Generation</strong>: We used the <strong>EleutherAI/gpt-neo-2.7B</strong> model for generating coherent and contextually relevant text based on a given prompt.</li>
<li><strong>Image Recognition</strong>: For classifying images, we leveraged the pre-trained <strong>EfficientNet-B0</strong> model from PyTorch, known for its efficiency and accuracy.</li>
<li><strong>Speech to Text</strong>: Utilizing the <strong>SpeechRecognition</strong> library, we implemented speech-to-text capabilities to convert spoken language into written text.</li>
<li><strong>Text to Speech</strong>: The <strong>gTTS (Google Text-to-Speech)</strong> library was used to convert written text into spoken audio, ensuring natural and expressive speech synthesis.</li>
</ul>
<h2 id="2-fastapi-framework">2. FastAPI Framework<a hidden class="anchor" aria-hidden="true" href="#2-fastapi-framework">#</a></h2>
<p>To build a robust and scalable backend, we employed the <strong>FastAPI</strong> framework. Its fast performance and intuitive design allowed us to create an API that efficiently handles requests for text generation, image recognition, and speech processing.</p>
<h2 id="3-gradio-interface">3. Gradio Interface<a hidden class="anchor" aria-hidden="true" href="#3-gradio-interface">#</a></h2>
<p>For a user-friendly interface, we turned to <strong>Gradio</strong>. This framework enabled us to build an interactive web application where users can easily interact with our multimodal AI system. Gradio&rsquo;s simplicity and flexibility made it the perfect choice for developing a seamless user experience.</p>
<h1 id="model-integration-and-workflow">Model Integration and Workflow<a hidden class="anchor" aria-hidden="true" href="#model-integration-and-workflow">#</a></h1>
<p>Our application seamlessly integrates different AI models and workflows to provide a comprehensive user experience:</p>
<ul>
<li><strong>Text Generation</strong>: Users input a prompt, and the GPT-Neo model generates a detailed and contextually appropriate response.</li>
<li><strong>Image Recognition</strong>: Users upload an image, which is then processed by the EfficientNet-B0 model to provide accurate classification results.</li>
<li><strong>Speech to Text</strong>: Users upload an audio file, and our system transcribes the speech into text using the SpeechRecognition library.</li>
<li><strong>Text to Speech</strong>: Users provide text input, and our application converts it into spoken audio using gTTS.</li>
</ul>
<h1 id="interactive-interface-gradio">Interactive Interface: Gradio<a hidden class="anchor" aria-hidden="true" href="#interactive-interface-gradio">#</a></h1>
<p>A powerful application needs a powerful interface. We crafted an intuitive web app with Gradio that allows users to effortlessly interact with our multimodal AI system. The interface features input fields for text, image, and audio uploads, providing a smooth and engaging user experience.</p>
<ul>
<li><strong>Text Generation Interface</strong>: Users enter a prompt and receive a generated text response.</li>
<li><strong>Image Recognition Interface</strong>: Users upload an image and receive classification results.</li>
<li><strong>Speech to Text Interface</strong>: Users upload an audio file and receive the transcribed text.</li>
<li><strong>Text to Speech Interface</strong>: Users enter text and receive synthesized speech output.</li>
</ul>
<h1 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h1>
<p>The Multimodal Generative AI project demonstrates the integration of multiple advanced AI technologies into a cohesive application, providing functionalities like text generation, image recognition, and speech processing. By leveraging modern frameworks and libraries, this project showcases the capabilities of generative and recognition systems, making it a comprehensive and advanced AI project.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://abirarsalane.github.io/tags/llm/">LLM</a></li>
      <li><a href="https://abirarsalane.github.io/tags/ai/">AI</a></li>
      <li><a href="https://abirarsalane.github.io/tags/genai/">GenAI</a></li>
      <li><a href="https://abirarsalane.github.io/tags/hugging-face/">Hugging Face</a></li>
      <li><a href="https://abirarsalane.github.io/tags/rag/">RAG</a></li>
      <li><a href="https://abirarsalane.github.io/tags/fine-tuning/">Fine-tuning</a></li>
      <li><a href="https://abirarsalane.github.io/tags/python/">Python</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://abirarsalane.github.io/">Abir Arsalane</a></span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
